{
 "cells": [
  {
   "cell_type": "code",
   "id": "51764ead",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-07T19:13:43.188476Z",
     "start_time": "2025-11-07T19:13:42.901427Z"
    }
   },
   "source": [
    "# Set seed for reproducibility\n",
    "SEED = 42\n",
    "\n",
    "# Import necessary libraries\n",
    "import os\n",
    "\n",
    "# Set environment variables before importing modules\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "os.environ['MPLCONFIGDIR'] = os.getcwd() + '/configs/'\n",
    "\n",
    "# Suppress warnings\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=Warning)\n",
    "\n",
    "# Import necessary modules\n",
    "import logging\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# Set seeds for random number generators in NumPy and Python\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "\n",
    "# Import PyTorch\n",
    "import torch\n",
    "torch.manual_seed(SEED)\n",
    "from torch import nn\n",
    "# from torchsummary import summary\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "logs_dir = \"tensorboard\"\n",
    "!pkill -f tensorboard\n",
    "%load_ext tensorboard\n",
    "!mkdir -p models\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "# Import other libraries\n",
    "import copy\n",
    "import shutil\n",
    "from itertools import product\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Configure plot display settings\n",
    "sns.set(font_scale=1.4)\n",
    "sns.set_style('white')\n",
    "plt.rc('font', size=14)\n",
    "%matplotlib inline"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n",
      "PyTorch version: 2.9.0\n",
      "Device: cpu\n"
     ]
    }
   ],
   "execution_count": 175
  },
  {
   "cell_type": "code",
   "id": "a5320974",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-07T19:13:43.374649Z",
     "start_time": "2025-11-07T19:13:43.205607Z"
    }
   },
   "source": [
    "# Read the dataset into a DataFrame with specified column names\n",
    "df = pd.read_csv('pirate_pain_train.csv', header=0)\n",
    "\n",
    "df_labels = pd.read_csv('pirate_pain_train_labels.csv', header=0)\n",
    "\n",
    "# Print the shape of the DataFrame\n",
    "print(f\"DataFrame shape: {df.shape}\")\n",
    "\n",
    "# Display the first 10 rows of the DataFrame\n",
    "df.head(10)"
   ],
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'pirate_pain_train.csv'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mFileNotFoundError\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[176]\u001B[39m\u001B[32m, line 2\u001B[39m\n\u001B[32m      1\u001B[39m \u001B[38;5;66;03m# Read the dataset into a DataFrame with specified column names\u001B[39;00m\n\u001B[32m----> \u001B[39m\u001B[32m2\u001B[39m df = \u001B[43mpd\u001B[49m\u001B[43m.\u001B[49m\u001B[43mread_csv\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mpirate_pain_train.csv\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mheader\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m0\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m      4\u001B[39m df_labels = pd.read_csv(\u001B[33m'\u001B[39m\u001B[33mpirate_pain_train_labels.csv\u001B[39m\u001B[33m'\u001B[39m, header=\u001B[32m0\u001B[39m)\n\u001B[32m      6\u001B[39m \u001B[38;5;66;03m# Print the shape of the DataFrame\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.pyenv/versions/ml/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1026\u001B[39m, in \u001B[36mread_csv\u001B[39m\u001B[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001B[39m\n\u001B[32m   1013\u001B[39m kwds_defaults = _refine_defaults_read(\n\u001B[32m   1014\u001B[39m     dialect,\n\u001B[32m   1015\u001B[39m     delimiter,\n\u001B[32m   (...)\u001B[39m\u001B[32m   1022\u001B[39m     dtype_backend=dtype_backend,\n\u001B[32m   1023\u001B[39m )\n\u001B[32m   1024\u001B[39m kwds.update(kwds_defaults)\n\u001B[32m-> \u001B[39m\u001B[32m1026\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_read\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.pyenv/versions/ml/lib/python3.11/site-packages/pandas/io/parsers/readers.py:620\u001B[39m, in \u001B[36m_read\u001B[39m\u001B[34m(filepath_or_buffer, kwds)\u001B[39m\n\u001B[32m    617\u001B[39m _validate_names(kwds.get(\u001B[33m\"\u001B[39m\u001B[33mnames\u001B[39m\u001B[33m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m))\n\u001B[32m    619\u001B[39m \u001B[38;5;66;03m# Create the parser.\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m620\u001B[39m parser = \u001B[43mTextFileReader\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    622\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m chunksize \u001B[38;5;129;01mor\u001B[39;00m iterator:\n\u001B[32m    623\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m parser\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.pyenv/versions/ml/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1620\u001B[39m, in \u001B[36mTextFileReader.__init__\u001B[39m\u001B[34m(self, f, engine, **kwds)\u001B[39m\n\u001B[32m   1617\u001B[39m     \u001B[38;5;28mself\u001B[39m.options[\u001B[33m\"\u001B[39m\u001B[33mhas_index_names\u001B[39m\u001B[33m\"\u001B[39m] = kwds[\u001B[33m\"\u001B[39m\u001B[33mhas_index_names\u001B[39m\u001B[33m\"\u001B[39m]\n\u001B[32m   1619\u001B[39m \u001B[38;5;28mself\u001B[39m.handles: IOHandles | \u001B[38;5;28;01mNone\u001B[39;00m = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m1620\u001B[39m \u001B[38;5;28mself\u001B[39m._engine = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_make_engine\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mengine\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.pyenv/versions/ml/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1880\u001B[39m, in \u001B[36mTextFileReader._make_engine\u001B[39m\u001B[34m(self, f, engine)\u001B[39m\n\u001B[32m   1878\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[33m\"\u001B[39m\u001B[33mb\u001B[39m\u001B[33m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m mode:\n\u001B[32m   1879\u001B[39m         mode += \u001B[33m\"\u001B[39m\u001B[33mb\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m-> \u001B[39m\u001B[32m1880\u001B[39m \u001B[38;5;28mself\u001B[39m.handles = \u001B[43mget_handle\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1881\u001B[39m \u001B[43m    \u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1882\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1883\u001B[39m \u001B[43m    \u001B[49m\u001B[43mencoding\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43moptions\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mencoding\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1884\u001B[39m \u001B[43m    \u001B[49m\u001B[43mcompression\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43moptions\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mcompression\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1885\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmemory_map\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43moptions\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mmemory_map\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1886\u001B[39m \u001B[43m    \u001B[49m\u001B[43mis_text\u001B[49m\u001B[43m=\u001B[49m\u001B[43mis_text\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1887\u001B[39m \u001B[43m    \u001B[49m\u001B[43merrors\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43moptions\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mencoding_errors\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mstrict\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1888\u001B[39m \u001B[43m    \u001B[49m\u001B[43mstorage_options\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43moptions\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mstorage_options\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1889\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1890\u001B[39m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m.handles \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1891\u001B[39m f = \u001B[38;5;28mself\u001B[39m.handles.handle\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.pyenv/versions/ml/lib/python3.11/site-packages/pandas/io/common.py:873\u001B[39m, in \u001B[36mget_handle\u001B[39m\u001B[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001B[39m\n\u001B[32m    868\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(handle, \u001B[38;5;28mstr\u001B[39m):\n\u001B[32m    869\u001B[39m     \u001B[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001B[39;00m\n\u001B[32m    870\u001B[39m     \u001B[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001B[39;00m\n\u001B[32m    871\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m ioargs.encoding \u001B[38;5;129;01mand\u001B[39;00m \u001B[33m\"\u001B[39m\u001B[33mb\u001B[39m\u001B[33m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m ioargs.mode:\n\u001B[32m    872\u001B[39m         \u001B[38;5;66;03m# Encoding\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m873\u001B[39m         handle = \u001B[38;5;28mopen\u001B[39m(\n\u001B[32m    874\u001B[39m             handle,\n\u001B[32m    875\u001B[39m             ioargs.mode,\n\u001B[32m    876\u001B[39m             encoding=ioargs.encoding,\n\u001B[32m    877\u001B[39m             errors=errors,\n\u001B[32m    878\u001B[39m             newline=\u001B[33m\"\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m    879\u001B[39m         )\n\u001B[32m    880\u001B[39m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    881\u001B[39m         \u001B[38;5;66;03m# Binary mode\u001B[39;00m\n\u001B[32m    882\u001B[39m         handle = \u001B[38;5;28mopen\u001B[39m(handle, ioargs.mode)\n",
      "\u001B[31mFileNotFoundError\u001B[39m: [Errno 2] No such file or directory: 'pirate_pain_train.csv'"
     ]
    }
   ],
   "execution_count": 176
  },
  {
   "cell_type": "code",
   "id": "b9c06179",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-07T19:13:43.384695Z",
     "start_time": "2025-11-07T18:35:34.011660Z"
    }
   },
   "source": [
    "# NOTE: These could be removed OR REMOVE THE DATAPOINTS WITH THESE DIFFERENT FROM 2\n",
    "print(df[\"n_legs\"].value_counts())\n",
    "print(df[\"n_hands\"].value_counts())\n",
    "print(df[\"n_eyes\"].value_counts())"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_legs\n",
      "two            104800\n",
      "one+peg_leg       960\n",
      "Name: count, dtype: int64\n",
      "n_hands\n",
      "two              104800\n",
      "one+hook_hand       960\n",
      "Name: count, dtype: int64\n",
      "n_eyes\n",
      "two              104800\n",
      "one+eye_patch       960\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "execution_count": 146
  },
  {
   "cell_type": "code",
   "id": "0cc6fb96",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-07T19:13:43.386129Z",
     "start_time": "2025-11-07T18:35:34.099461Z"
    }
   },
   "source": [
    "float_cols = df.select_dtypes(include=['float64']).columns\n",
    "for col in float_cols:\n",
    "    df[col] = df[col].astype(np.float32)"
   ],
   "outputs": [],
   "execution_count": 147
  },
  {
   "cell_type": "code",
   "id": "a93d4ace",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-07T19:13:43.386872Z",
     "start_time": "2025-11-07T18:35:34.148446Z"
    }
   },
   "source": [
    "df.info()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 105760 entries, 0 to 105759\n",
      "Data columns (total 40 columns):\n",
      " #   Column         Non-Null Count   Dtype  \n",
      "---  ------         --------------   -----  \n",
      " 0   sample_index   105760 non-null  int64  \n",
      " 1   time           105760 non-null  int64  \n",
      " 2   pain_survey_1  105760 non-null  int64  \n",
      " 3   pain_survey_2  105760 non-null  int64  \n",
      " 4   pain_survey_3  105760 non-null  int64  \n",
      " 5   pain_survey_4  105760 non-null  int64  \n",
      " 6   n_legs         105760 non-null  object \n",
      " 7   n_hands        105760 non-null  object \n",
      " 8   n_eyes         105760 non-null  object \n",
      " 9   joint_00       105760 non-null  float32\n",
      " 10  joint_01       105760 non-null  float32\n",
      " 11  joint_02       105760 non-null  float32\n",
      " 12  joint_03       105760 non-null  float32\n",
      " 13  joint_04       105760 non-null  float32\n",
      " 14  joint_05       105760 non-null  float32\n",
      " 15  joint_06       105760 non-null  float32\n",
      " 16  joint_07       105760 non-null  float32\n",
      " 17  joint_08       105760 non-null  float32\n",
      " 18  joint_09       105760 non-null  float32\n",
      " 19  joint_10       105760 non-null  float32\n",
      " 20  joint_11       105760 non-null  float32\n",
      " 21  joint_12       105760 non-null  float32\n",
      " 22  joint_13       105760 non-null  float32\n",
      " 23  joint_14       105760 non-null  float32\n",
      " 24  joint_15       105760 non-null  float32\n",
      " 25  joint_16       105760 non-null  float32\n",
      " 26  joint_17       105760 non-null  float32\n",
      " 27  joint_18       105760 non-null  float32\n",
      " 28  joint_19       105760 non-null  float32\n",
      " 29  joint_20       105760 non-null  float32\n",
      " 30  joint_21       105760 non-null  float32\n",
      " 31  joint_22       105760 non-null  float32\n",
      " 32  joint_23       105760 non-null  float32\n",
      " 33  joint_24       105760 non-null  float32\n",
      " 34  joint_25       105760 non-null  float32\n",
      " 35  joint_26       105760 non-null  float32\n",
      " 36  joint_27       105760 non-null  float32\n",
      " 37  joint_28       105760 non-null  float32\n",
      " 38  joint_29       105760 non-null  float32\n",
      " 39  joint_30       105760 non-null  float32\n",
      "dtypes: float32(31), int64(6), object(3)\n",
      "memory usage: 19.8+ MB\n"
     ]
    }
   ],
   "execution_count": 148
  },
  {
   "cell_type": "code",
   "id": "b99ed791",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-07T19:13:43.387132Z",
     "start_time": "2025-11-07T18:35:34.185075Z"
    }
   },
   "source": [
    "df.drop(columns=[\"n_legs\", \"n_hands\", \"n_eyes\"], inplace=True)"
   ],
   "outputs": [],
   "execution_count": 149
  },
  {
   "cell_type": "code",
   "id": "f1712ef8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-07T19:13:43.387640Z",
     "start_time": "2025-11-07T18:35:34.208093Z"
    }
   },
   "source": [
    "df.head(5)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   sample_index  time  pain_survey_1  pain_survey_2  pain_survey_3  \\\n",
       "0             0     0              2              0              2   \n",
       "1             0     1              2              2              2   \n",
       "2             0     2              2              0              2   \n",
       "3             0     3              2              2              2   \n",
       "4             0     4              2              2              2   \n",
       "\n",
       "   pain_survey_4  joint_00  joint_01  joint_02  joint_03  ...      joint_21  \\\n",
       "0              1  1.094705  0.985281  1.018302  1.010385  ...  3.499558e-06   \n",
       "1              2  1.135183  1.021175  0.994343  1.052364  ...  3.976952e-07   \n",
       "2              2  1.080745  0.962842  1.009588  0.977169  ...  1.533820e-07   \n",
       "3              2  0.938017  1.081592  0.998021  0.987283  ...  1.006865e-05   \n",
       "4              2  1.090185  1.032145  1.008710  0.963658  ...  4.437265e-06   \n",
       "\n",
       "       joint_22  joint_23      joint_24  joint_25  joint_26  joint_27  \\\n",
       "0  1.945042e-06  0.000004  1.153299e-05  0.000004  0.017592  0.013508   \n",
       "1  6.765108e-07  0.000006  4.643774e-08  0.000000  0.013352  0.000000   \n",
       "2  1.698525e-07  0.000001  2.424536e-06  0.000003  0.016225  0.008110   \n",
       "3  5.511079e-07  0.000002  5.432416e-08  0.000000  0.011832  0.007450   \n",
       "4  1.735459e-07  0.000002  5.825366e-08  0.000007  0.005360  0.002532   \n",
       "\n",
       "   joint_28  joint_29  joint_30  \n",
       "0  0.026798  0.027815       0.5  \n",
       "1  0.013377  0.013716       0.5  \n",
       "2  0.024097  0.023105       0.5  \n",
       "3  0.028613  0.024648       0.5  \n",
       "4  0.033026  0.025328       0.5  \n",
       "\n",
       "[5 rows x 37 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_index</th>\n",
       "      <th>time</th>\n",
       "      <th>pain_survey_1</th>\n",
       "      <th>pain_survey_2</th>\n",
       "      <th>pain_survey_3</th>\n",
       "      <th>pain_survey_4</th>\n",
       "      <th>joint_00</th>\n",
       "      <th>joint_01</th>\n",
       "      <th>joint_02</th>\n",
       "      <th>joint_03</th>\n",
       "      <th>...</th>\n",
       "      <th>joint_21</th>\n",
       "      <th>joint_22</th>\n",
       "      <th>joint_23</th>\n",
       "      <th>joint_24</th>\n",
       "      <th>joint_25</th>\n",
       "      <th>joint_26</th>\n",
       "      <th>joint_27</th>\n",
       "      <th>joint_28</th>\n",
       "      <th>joint_29</th>\n",
       "      <th>joint_30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.094705</td>\n",
       "      <td>0.985281</td>\n",
       "      <td>1.018302</td>\n",
       "      <td>1.010385</td>\n",
       "      <td>...</td>\n",
       "      <td>3.499558e-06</td>\n",
       "      <td>1.945042e-06</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>1.153299e-05</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.017592</td>\n",
       "      <td>0.013508</td>\n",
       "      <td>0.026798</td>\n",
       "      <td>0.027815</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.135183</td>\n",
       "      <td>1.021175</td>\n",
       "      <td>0.994343</td>\n",
       "      <td>1.052364</td>\n",
       "      <td>...</td>\n",
       "      <td>3.976952e-07</td>\n",
       "      <td>6.765108e-07</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>4.643774e-08</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013352</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013377</td>\n",
       "      <td>0.013716</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.080745</td>\n",
       "      <td>0.962842</td>\n",
       "      <td>1.009588</td>\n",
       "      <td>0.977169</td>\n",
       "      <td>...</td>\n",
       "      <td>1.533820e-07</td>\n",
       "      <td>1.698525e-07</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>2.424536e-06</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.016225</td>\n",
       "      <td>0.008110</td>\n",
       "      <td>0.024097</td>\n",
       "      <td>0.023105</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.938017</td>\n",
       "      <td>1.081592</td>\n",
       "      <td>0.998021</td>\n",
       "      <td>0.987283</td>\n",
       "      <td>...</td>\n",
       "      <td>1.006865e-05</td>\n",
       "      <td>5.511079e-07</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>5.432416e-08</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011832</td>\n",
       "      <td>0.007450</td>\n",
       "      <td>0.028613</td>\n",
       "      <td>0.024648</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.090185</td>\n",
       "      <td>1.032145</td>\n",
       "      <td>1.008710</td>\n",
       "      <td>0.963658</td>\n",
       "      <td>...</td>\n",
       "      <td>4.437265e-06</td>\n",
       "      <td>1.735459e-07</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>5.825366e-08</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.005360</td>\n",
       "      <td>0.002532</td>\n",
       "      <td>0.033026</td>\n",
       "      <td>0.025328</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 37 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 150
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-07T19:13:43.388889Z",
     "start_time": "2025-11-07T18:35:34.261292Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# NOTE: it might be that the surveys are not really useful, a lot are close to 2\n",
    "df.describe()"
   ],
   "id": "1446d9d4",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        sample_index           time  pain_survey_1  pain_survey_2  \\\n",
       "count  105760.000000  105760.000000  105760.000000  105760.000000   \n",
       "mean      330.000000      79.500000       1.633746       1.654851   \n",
       "std       190.814948      46.187338       0.682423       0.669639   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%       165.000000      39.750000       2.000000       2.000000   \n",
       "50%       330.000000      79.500000       2.000000       2.000000   \n",
       "75%       495.000000     119.250000       2.000000       2.000000   \n",
       "max       660.000000     159.000000       2.000000       2.000000   \n",
       "\n",
       "       pain_survey_3  pain_survey_4       joint_00       joint_01  \\\n",
       "count  105760.000000  105760.000000  105760.000000  105760.000000   \n",
       "mean        1.653640       1.663134       0.943095       0.916955   \n",
       "std         0.666649       0.661994       0.202051       0.197608   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         2.000000       2.000000       0.828277       0.811445   \n",
       "50%         2.000000       2.000000       1.005126       0.979468   \n",
       "75%         2.000000       2.000000       1.081039       1.056611   \n",
       "max         2.000000       2.000000       1.407968       1.334613   \n",
       "\n",
       "            joint_02       joint_03  ...      joint_21      joint_22  \\\n",
       "count  105760.000000  105760.000000  ...  1.057600e+05  1.057600e+05   \n",
       "mean        0.779296       0.767921  ...  3.972126e-05  4.176794e-05   \n",
       "std         0.295605       0.300787  ...  4.974496e-03  5.472244e-03   \n",
       "min         0.001015       0.005403  ...  0.000000e+00  1.510494e-07   \n",
       "25%         0.568850       0.520020  ...  6.545878e-08  3.321650e-07   \n",
       "50%         0.909549       0.914834  ...  8.302747e-07  1.095971e-06   \n",
       "75%         0.995187       0.994324  ...  2.800090e-06  3.079464e-06   \n",
       "max         1.306046       1.254729  ...  1.442198e+00  1.305001e+00   \n",
       "\n",
       "           joint_23      joint_24      joint_25       joint_26       joint_27  \\\n",
       "count  1.057600e+05  1.057600e+05  1.057600e+05  105760.000000  105760.000000   \n",
       "mean   3.561780e-05  3.138109e-05  1.024604e-04       0.041905       0.058244   \n",
       "std    1.235449e-03  4.062914e-04  3.206128e-03       0.060293       0.079819   \n",
       "min    0.000000e+00  1.063144e-08  0.000000e+00       0.000203       0.000000   \n",
       "25%    3.275038e-07  2.841805e-07  7.161332e-07       0.009885       0.012652   \n",
       "50%    1.024209e-06  8.746148e-07  3.126723e-06       0.021898       0.031739   \n",
       "75%    3.021830e-06  2.507548e-06  9.946107e-06       0.048579       0.071051   \n",
       "max    2.742411e-01  3.643074e-02  9.473540e-01       1.223617       1.187419   \n",
       "\n",
       "            joint_28       joint_29  joint_30  \n",
       "count  105760.000000  105760.000000  105760.0  \n",
       "mean        0.049886       0.062273       0.5  \n",
       "std         0.060773       0.072597       0.0  \n",
       "min         0.000000       0.000000       0.5  \n",
       "25%         0.016290       0.019638       0.5  \n",
       "50%         0.031843       0.039041       0.5  \n",
       "75%         0.058741       0.079518       0.5  \n",
       "max         1.412037       1.370765       0.5  \n",
       "\n",
       "[8 rows x 37 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_index</th>\n",
       "      <th>time</th>\n",
       "      <th>pain_survey_1</th>\n",
       "      <th>pain_survey_2</th>\n",
       "      <th>pain_survey_3</th>\n",
       "      <th>pain_survey_4</th>\n",
       "      <th>joint_00</th>\n",
       "      <th>joint_01</th>\n",
       "      <th>joint_02</th>\n",
       "      <th>joint_03</th>\n",
       "      <th>...</th>\n",
       "      <th>joint_21</th>\n",
       "      <th>joint_22</th>\n",
       "      <th>joint_23</th>\n",
       "      <th>joint_24</th>\n",
       "      <th>joint_25</th>\n",
       "      <th>joint_26</th>\n",
       "      <th>joint_27</th>\n",
       "      <th>joint_28</th>\n",
       "      <th>joint_29</th>\n",
       "      <th>joint_30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>105760.000000</td>\n",
       "      <td>105760.000000</td>\n",
       "      <td>105760.000000</td>\n",
       "      <td>105760.000000</td>\n",
       "      <td>105760.000000</td>\n",
       "      <td>105760.000000</td>\n",
       "      <td>105760.000000</td>\n",
       "      <td>105760.000000</td>\n",
       "      <td>105760.000000</td>\n",
       "      <td>105760.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.057600e+05</td>\n",
       "      <td>1.057600e+05</td>\n",
       "      <td>1.057600e+05</td>\n",
       "      <td>1.057600e+05</td>\n",
       "      <td>1.057600e+05</td>\n",
       "      <td>105760.000000</td>\n",
       "      <td>105760.000000</td>\n",
       "      <td>105760.000000</td>\n",
       "      <td>105760.000000</td>\n",
       "      <td>105760.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>330.000000</td>\n",
       "      <td>79.500000</td>\n",
       "      <td>1.633746</td>\n",
       "      <td>1.654851</td>\n",
       "      <td>1.653640</td>\n",
       "      <td>1.663134</td>\n",
       "      <td>0.943095</td>\n",
       "      <td>0.916955</td>\n",
       "      <td>0.779296</td>\n",
       "      <td>0.767921</td>\n",
       "      <td>...</td>\n",
       "      <td>3.972126e-05</td>\n",
       "      <td>4.176794e-05</td>\n",
       "      <td>3.561780e-05</td>\n",
       "      <td>3.138109e-05</td>\n",
       "      <td>1.024604e-04</td>\n",
       "      <td>0.041905</td>\n",
       "      <td>0.058244</td>\n",
       "      <td>0.049886</td>\n",
       "      <td>0.062273</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>190.814948</td>\n",
       "      <td>46.187338</td>\n",
       "      <td>0.682423</td>\n",
       "      <td>0.669639</td>\n",
       "      <td>0.666649</td>\n",
       "      <td>0.661994</td>\n",
       "      <td>0.202051</td>\n",
       "      <td>0.197608</td>\n",
       "      <td>0.295605</td>\n",
       "      <td>0.300787</td>\n",
       "      <td>...</td>\n",
       "      <td>4.974496e-03</td>\n",
       "      <td>5.472244e-03</td>\n",
       "      <td>1.235449e-03</td>\n",
       "      <td>4.062914e-04</td>\n",
       "      <td>3.206128e-03</td>\n",
       "      <td>0.060293</td>\n",
       "      <td>0.079819</td>\n",
       "      <td>0.060773</td>\n",
       "      <td>0.072597</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001015</td>\n",
       "      <td>0.005403</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.510494e-07</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.063144e-08</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000203</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>165.000000</td>\n",
       "      <td>39.750000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.828277</td>\n",
       "      <td>0.811445</td>\n",
       "      <td>0.568850</td>\n",
       "      <td>0.520020</td>\n",
       "      <td>...</td>\n",
       "      <td>6.545878e-08</td>\n",
       "      <td>3.321650e-07</td>\n",
       "      <td>3.275038e-07</td>\n",
       "      <td>2.841805e-07</td>\n",
       "      <td>7.161332e-07</td>\n",
       "      <td>0.009885</td>\n",
       "      <td>0.012652</td>\n",
       "      <td>0.016290</td>\n",
       "      <td>0.019638</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>330.000000</td>\n",
       "      <td>79.500000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.005126</td>\n",
       "      <td>0.979468</td>\n",
       "      <td>0.909549</td>\n",
       "      <td>0.914834</td>\n",
       "      <td>...</td>\n",
       "      <td>8.302747e-07</td>\n",
       "      <td>1.095971e-06</td>\n",
       "      <td>1.024209e-06</td>\n",
       "      <td>8.746148e-07</td>\n",
       "      <td>3.126723e-06</td>\n",
       "      <td>0.021898</td>\n",
       "      <td>0.031739</td>\n",
       "      <td>0.031843</td>\n",
       "      <td>0.039041</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>495.000000</td>\n",
       "      <td>119.250000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.081039</td>\n",
       "      <td>1.056611</td>\n",
       "      <td>0.995187</td>\n",
       "      <td>0.994324</td>\n",
       "      <td>...</td>\n",
       "      <td>2.800090e-06</td>\n",
       "      <td>3.079464e-06</td>\n",
       "      <td>3.021830e-06</td>\n",
       "      <td>2.507548e-06</td>\n",
       "      <td>9.946107e-06</td>\n",
       "      <td>0.048579</td>\n",
       "      <td>0.071051</td>\n",
       "      <td>0.058741</td>\n",
       "      <td>0.079518</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>660.000000</td>\n",
       "      <td>159.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.407968</td>\n",
       "      <td>1.334613</td>\n",
       "      <td>1.306046</td>\n",
       "      <td>1.254729</td>\n",
       "      <td>...</td>\n",
       "      <td>1.442198e+00</td>\n",
       "      <td>1.305001e+00</td>\n",
       "      <td>2.742411e-01</td>\n",
       "      <td>3.643074e-02</td>\n",
       "      <td>9.473540e-01</td>\n",
       "      <td>1.223617</td>\n",
       "      <td>1.187419</td>\n",
       "      <td>1.412037</td>\n",
       "      <td>1.370765</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 37 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 151
  },
  {
   "cell_type": "code",
   "id": "67304d9b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-07T19:13:43.391433Z",
     "start_time": "2025-11-07T18:35:34.464624Z"
    }
   },
   "source": [
    "# NOTE: joint_30 is constant -> useless\n",
    "df.drop(columns=[\"joint_30\"], inplace=True)"
   ],
   "outputs": [],
   "execution_count": 152
  },
  {
   "cell_type": "code",
   "id": "be3b5150",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-07T19:13:43.392692Z",
     "start_time": "2025-11-07T18:35:34.563550Z"
    }
   },
   "source": [
    "# Check in each sample index if the survey value changes\n",
    "df.groupby(\"sample_index\").var()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                     time  pain_survey_1  pain_survey_2  pain_survey_3  \\\n",
       "sample_index                                                             \n",
       "0             2146.666667       0.578459       0.453420       0.370912   \n",
       "1             2146.666667       0.518239       0.427634       0.520597   \n",
       "2             2146.666667       0.232665       0.303420       0.348703   \n",
       "3             2146.666667       0.270401       0.451415       0.410024   \n",
       "4             2146.666667       0.367885       0.349017       0.417256   \n",
       "...                   ...            ...            ...            ...   \n",
       "656           2146.666667       0.384866       0.463994       0.482351   \n",
       "657           2146.666667       0.614937       0.387421       0.527319   \n",
       "658           2146.666667       0.400000       0.447170       0.308019   \n",
       "659           2146.666667       0.301258       0.392099       0.361281   \n",
       "660           2146.666667       0.534237       0.438836       0.526690   \n",
       "\n",
       "              pain_survey_4  joint_00  joint_01  joint_02  joint_03  joint_04  \\\n",
       "sample_index                                                                    \n",
       "0                  0.341785  0.002779  0.002312  0.001449  0.001620  0.001546   \n",
       "1                  0.285181  0.002029  0.002002  0.001327  0.001203  0.001545   \n",
       "2                  0.590212  0.003289  0.002869  0.013190  0.002108  0.001255   \n",
       "3                  0.389308  0.002848  0.002170  0.001496  0.002012  0.001289   \n",
       "4                  0.560377  0.001996  0.001848  0.001527  0.001507  0.001339   \n",
       "...                     ...       ...       ...       ...       ...       ...   \n",
       "656                0.382036  0.002239  0.002606  0.001674  0.001667  0.000694   \n",
       "657                0.465252  0.013406  0.010557  0.034879  0.036366  0.098422   \n",
       "658                0.564112  0.002130  0.002614  0.001623  0.001798  0.001164   \n",
       "659                0.272602  0.001928  0.002839  0.001388  0.001453  0.001260   \n",
       "660                0.399017  0.002629  0.002081  0.001632  0.001667  0.001279   \n",
       "\n",
       "              ...      joint_20      joint_21      joint_22      joint_23  \\\n",
       "sample_index  ...                                                           \n",
       "0             ...  2.765450e-09  1.121023e-08  1.030416e-10  3.507136e-11   \n",
       "1             ...  1.202635e-10  1.203627e-12  9.048194e-13  1.132519e-12   \n",
       "2             ...  2.271433e-10  3.516154e-11  7.492228e-10  6.843855e-09   \n",
       "3             ...  6.908745e-11  2.097331e-12  1.303198e-12  1.280051e-12   \n",
       "4             ...  9.357456e-11  1.002201e-12  1.793468e-12  1.359855e-12   \n",
       "...           ...           ...           ...           ...           ...   \n",
       "656           ...  3.781578e-06  2.390680e-09  1.236089e-08  8.372293e-08   \n",
       "657           ...  4.199002e-05  1.540430e-07  3.065419e-08  4.670098e-07   \n",
       "658           ...  1.071635e-10  5.172513e-12  7.039511e-12  7.257495e-12   \n",
       "659           ...  6.925451e-11  3.340236e-12  6.567325e-12  6.956377e-12   \n",
       "660           ...  7.784415e-11  1.026504e-12  1.105003e-12  1.074981e-12   \n",
       "\n",
       "                  joint_24      joint_25  joint_26  joint_27  joint_28  \\\n",
       "sample_index                                                             \n",
       "0             4.065838e-11  1.399554e-09  0.000316  0.000213  0.000239   \n",
       "1             7.930838e-13  8.677363e-12  0.000704  0.001049  0.005088   \n",
       "2             1.991356e-09  1.672197e-08  0.024022  0.009626  0.000732   \n",
       "3             7.887789e-13  9.435219e-11  0.000492  0.001027  0.000641   \n",
       "4             2.161616e-12  6.887033e-12  0.000216  0.000199  0.000043   \n",
       "...                    ...           ...       ...       ...       ...   \n",
       "656           2.021945e-08  4.956993e-07  0.000004  0.000005  0.000016   \n",
       "657           3.461188e-07  2.265925e-06  0.000382  0.000645  0.000263   \n",
       "658           2.155900e-12  1.572881e-10  0.000746  0.001668  0.001004   \n",
       "659           1.443975e-12  2.535323e-10  0.000373  0.000236  0.000633   \n",
       "660           7.787508e-13  6.221027e-12  0.000475  0.000385  0.018251   \n",
       "\n",
       "              joint_29  \n",
       "sample_index            \n",
       "0             0.000336  \n",
       "1             0.001512  \n",
       "2             0.000477  \n",
       "3             0.000489  \n",
       "4             0.000103  \n",
       "...                ...  \n",
       "656           0.000021  \n",
       "657           0.003186  \n",
       "658           0.000875  \n",
       "659           0.002056  \n",
       "660           0.001960  \n",
       "\n",
       "[661 rows x 35 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>pain_survey_1</th>\n",
       "      <th>pain_survey_2</th>\n",
       "      <th>pain_survey_3</th>\n",
       "      <th>pain_survey_4</th>\n",
       "      <th>joint_00</th>\n",
       "      <th>joint_01</th>\n",
       "      <th>joint_02</th>\n",
       "      <th>joint_03</th>\n",
       "      <th>joint_04</th>\n",
       "      <th>...</th>\n",
       "      <th>joint_20</th>\n",
       "      <th>joint_21</th>\n",
       "      <th>joint_22</th>\n",
       "      <th>joint_23</th>\n",
       "      <th>joint_24</th>\n",
       "      <th>joint_25</th>\n",
       "      <th>joint_26</th>\n",
       "      <th>joint_27</th>\n",
       "      <th>joint_28</th>\n",
       "      <th>joint_29</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sample_index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2146.666667</td>\n",
       "      <td>0.578459</td>\n",
       "      <td>0.453420</td>\n",
       "      <td>0.370912</td>\n",
       "      <td>0.341785</td>\n",
       "      <td>0.002779</td>\n",
       "      <td>0.002312</td>\n",
       "      <td>0.001449</td>\n",
       "      <td>0.001620</td>\n",
       "      <td>0.001546</td>\n",
       "      <td>...</td>\n",
       "      <td>2.765450e-09</td>\n",
       "      <td>1.121023e-08</td>\n",
       "      <td>1.030416e-10</td>\n",
       "      <td>3.507136e-11</td>\n",
       "      <td>4.065838e-11</td>\n",
       "      <td>1.399554e-09</td>\n",
       "      <td>0.000316</td>\n",
       "      <td>0.000213</td>\n",
       "      <td>0.000239</td>\n",
       "      <td>0.000336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2146.666667</td>\n",
       "      <td>0.518239</td>\n",
       "      <td>0.427634</td>\n",
       "      <td>0.520597</td>\n",
       "      <td>0.285181</td>\n",
       "      <td>0.002029</td>\n",
       "      <td>0.002002</td>\n",
       "      <td>0.001327</td>\n",
       "      <td>0.001203</td>\n",
       "      <td>0.001545</td>\n",
       "      <td>...</td>\n",
       "      <td>1.202635e-10</td>\n",
       "      <td>1.203627e-12</td>\n",
       "      <td>9.048194e-13</td>\n",
       "      <td>1.132519e-12</td>\n",
       "      <td>7.930838e-13</td>\n",
       "      <td>8.677363e-12</td>\n",
       "      <td>0.000704</td>\n",
       "      <td>0.001049</td>\n",
       "      <td>0.005088</td>\n",
       "      <td>0.001512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2146.666667</td>\n",
       "      <td>0.232665</td>\n",
       "      <td>0.303420</td>\n",
       "      <td>0.348703</td>\n",
       "      <td>0.590212</td>\n",
       "      <td>0.003289</td>\n",
       "      <td>0.002869</td>\n",
       "      <td>0.013190</td>\n",
       "      <td>0.002108</td>\n",
       "      <td>0.001255</td>\n",
       "      <td>...</td>\n",
       "      <td>2.271433e-10</td>\n",
       "      <td>3.516154e-11</td>\n",
       "      <td>7.492228e-10</td>\n",
       "      <td>6.843855e-09</td>\n",
       "      <td>1.991356e-09</td>\n",
       "      <td>1.672197e-08</td>\n",
       "      <td>0.024022</td>\n",
       "      <td>0.009626</td>\n",
       "      <td>0.000732</td>\n",
       "      <td>0.000477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2146.666667</td>\n",
       "      <td>0.270401</td>\n",
       "      <td>0.451415</td>\n",
       "      <td>0.410024</td>\n",
       "      <td>0.389308</td>\n",
       "      <td>0.002848</td>\n",
       "      <td>0.002170</td>\n",
       "      <td>0.001496</td>\n",
       "      <td>0.002012</td>\n",
       "      <td>0.001289</td>\n",
       "      <td>...</td>\n",
       "      <td>6.908745e-11</td>\n",
       "      <td>2.097331e-12</td>\n",
       "      <td>1.303198e-12</td>\n",
       "      <td>1.280051e-12</td>\n",
       "      <td>7.887789e-13</td>\n",
       "      <td>9.435219e-11</td>\n",
       "      <td>0.000492</td>\n",
       "      <td>0.001027</td>\n",
       "      <td>0.000641</td>\n",
       "      <td>0.000489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2146.666667</td>\n",
       "      <td>0.367885</td>\n",
       "      <td>0.349017</td>\n",
       "      <td>0.417256</td>\n",
       "      <td>0.560377</td>\n",
       "      <td>0.001996</td>\n",
       "      <td>0.001848</td>\n",
       "      <td>0.001527</td>\n",
       "      <td>0.001507</td>\n",
       "      <td>0.001339</td>\n",
       "      <td>...</td>\n",
       "      <td>9.357456e-11</td>\n",
       "      <td>1.002201e-12</td>\n",
       "      <td>1.793468e-12</td>\n",
       "      <td>1.359855e-12</td>\n",
       "      <td>2.161616e-12</td>\n",
       "      <td>6.887033e-12</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>0.000199</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>0.000103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>656</th>\n",
       "      <td>2146.666667</td>\n",
       "      <td>0.384866</td>\n",
       "      <td>0.463994</td>\n",
       "      <td>0.482351</td>\n",
       "      <td>0.382036</td>\n",
       "      <td>0.002239</td>\n",
       "      <td>0.002606</td>\n",
       "      <td>0.001674</td>\n",
       "      <td>0.001667</td>\n",
       "      <td>0.000694</td>\n",
       "      <td>...</td>\n",
       "      <td>3.781578e-06</td>\n",
       "      <td>2.390680e-09</td>\n",
       "      <td>1.236089e-08</td>\n",
       "      <td>8.372293e-08</td>\n",
       "      <td>2.021945e-08</td>\n",
       "      <td>4.956993e-07</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>657</th>\n",
       "      <td>2146.666667</td>\n",
       "      <td>0.614937</td>\n",
       "      <td>0.387421</td>\n",
       "      <td>0.527319</td>\n",
       "      <td>0.465252</td>\n",
       "      <td>0.013406</td>\n",
       "      <td>0.010557</td>\n",
       "      <td>0.034879</td>\n",
       "      <td>0.036366</td>\n",
       "      <td>0.098422</td>\n",
       "      <td>...</td>\n",
       "      <td>4.199002e-05</td>\n",
       "      <td>1.540430e-07</td>\n",
       "      <td>3.065419e-08</td>\n",
       "      <td>4.670098e-07</td>\n",
       "      <td>3.461188e-07</td>\n",
       "      <td>2.265925e-06</td>\n",
       "      <td>0.000382</td>\n",
       "      <td>0.000645</td>\n",
       "      <td>0.000263</td>\n",
       "      <td>0.003186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>658</th>\n",
       "      <td>2146.666667</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.447170</td>\n",
       "      <td>0.308019</td>\n",
       "      <td>0.564112</td>\n",
       "      <td>0.002130</td>\n",
       "      <td>0.002614</td>\n",
       "      <td>0.001623</td>\n",
       "      <td>0.001798</td>\n",
       "      <td>0.001164</td>\n",
       "      <td>...</td>\n",
       "      <td>1.071635e-10</td>\n",
       "      <td>5.172513e-12</td>\n",
       "      <td>7.039511e-12</td>\n",
       "      <td>7.257495e-12</td>\n",
       "      <td>2.155900e-12</td>\n",
       "      <td>1.572881e-10</td>\n",
       "      <td>0.000746</td>\n",
       "      <td>0.001668</td>\n",
       "      <td>0.001004</td>\n",
       "      <td>0.000875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>659</th>\n",
       "      <td>2146.666667</td>\n",
       "      <td>0.301258</td>\n",
       "      <td>0.392099</td>\n",
       "      <td>0.361281</td>\n",
       "      <td>0.272602</td>\n",
       "      <td>0.001928</td>\n",
       "      <td>0.002839</td>\n",
       "      <td>0.001388</td>\n",
       "      <td>0.001453</td>\n",
       "      <td>0.001260</td>\n",
       "      <td>...</td>\n",
       "      <td>6.925451e-11</td>\n",
       "      <td>3.340236e-12</td>\n",
       "      <td>6.567325e-12</td>\n",
       "      <td>6.956377e-12</td>\n",
       "      <td>1.443975e-12</td>\n",
       "      <td>2.535323e-10</td>\n",
       "      <td>0.000373</td>\n",
       "      <td>0.000236</td>\n",
       "      <td>0.000633</td>\n",
       "      <td>0.002056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>660</th>\n",
       "      <td>2146.666667</td>\n",
       "      <td>0.534237</td>\n",
       "      <td>0.438836</td>\n",
       "      <td>0.526690</td>\n",
       "      <td>0.399017</td>\n",
       "      <td>0.002629</td>\n",
       "      <td>0.002081</td>\n",
       "      <td>0.001632</td>\n",
       "      <td>0.001667</td>\n",
       "      <td>0.001279</td>\n",
       "      <td>...</td>\n",
       "      <td>7.784415e-11</td>\n",
       "      <td>1.026504e-12</td>\n",
       "      <td>1.105003e-12</td>\n",
       "      <td>1.074981e-12</td>\n",
       "      <td>7.787508e-13</td>\n",
       "      <td>6.221027e-12</td>\n",
       "      <td>0.000475</td>\n",
       "      <td>0.000385</td>\n",
       "      <td>0.018251</td>\n",
       "      <td>0.001960</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>661 rows × 35 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 153
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-07T19:13:43.394147Z",
     "start_time": "2025-11-07T18:35:34.634850Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Visualise the count of timestamps for each activity\n",
    "plt.figure(figsize=(17, 5))\n",
    "sns.countplot(\n",
    "    x='label',\n",
    "    data=df_labels,\n",
    "    order=df_labels['label'].value_counts().index,\n",
    "    palette='tab10'\n",
    ")\n",
    "\n",
    "# Set the title of the plot\n",
    "plt.title('Pain Scale Timestamps')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ],
   "id": "df1a2435ff3f1977",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1700x500 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 154
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-07T19:13:43.394401Z",
     "start_time": "2025-11-07T18:35:34.721726Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# All sample_indexes have the same number of timesteps\n",
    "df.groupby('sample_index').size().nunique() == 1"
   ],
   "id": "87e29a2a47d502b4",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 155
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-07T19:13:43.394625Z",
     "start_time": "2025-11-07T18:35:34.767793Z"
    }
   },
   "cell_type": "code",
   "source": "df = df.merge(df_labels, on='sample_index', how='left')",
   "id": "f5cc9d24555e3dc",
   "outputs": [],
   "execution_count": 156
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-07T19:13:43.394749Z",
     "start_time": "2025-11-07T18:35:34.825763Z"
    }
   },
   "cell_type": "code",
   "source": "df.head(5)",
   "id": "a8e3e3548bf1a980",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   sample_index  time  pain_survey_1  pain_survey_2  pain_survey_3  \\\n",
       "0             0     0              2              0              2   \n",
       "1             0     1              2              2              2   \n",
       "2             0     2              2              0              2   \n",
       "3             0     3              2              2              2   \n",
       "4             0     4              2              2              2   \n",
       "\n",
       "   pain_survey_4  joint_00  joint_01  joint_02  joint_03  ...      joint_21  \\\n",
       "0              1  1.094705  0.985281  1.018302  1.010385  ...  3.499558e-06   \n",
       "1              2  1.135183  1.021175  0.994343  1.052364  ...  3.976952e-07   \n",
       "2              2  1.080745  0.962842  1.009588  0.977169  ...  1.533820e-07   \n",
       "3              2  0.938017  1.081592  0.998021  0.987283  ...  1.006865e-05   \n",
       "4              2  1.090185  1.032145  1.008710  0.963658  ...  4.437265e-06   \n",
       "\n",
       "       joint_22  joint_23      joint_24  joint_25  joint_26  joint_27  \\\n",
       "0  1.945042e-06  0.000004  1.153299e-05  0.000004  0.017592  0.013508   \n",
       "1  6.765108e-07  0.000006  4.643774e-08  0.000000  0.013352  0.000000   \n",
       "2  1.698525e-07  0.000001  2.424536e-06  0.000003  0.016225  0.008110   \n",
       "3  5.511079e-07  0.000002  5.432416e-08  0.000000  0.011832  0.007450   \n",
       "4  1.735459e-07  0.000002  5.825366e-08  0.000007  0.005360  0.002532   \n",
       "\n",
       "   joint_28  joint_29    label  \n",
       "0  0.026798  0.027815  no_pain  \n",
       "1  0.013377  0.013716  no_pain  \n",
       "2  0.024097  0.023105  no_pain  \n",
       "3  0.028613  0.024648  no_pain  \n",
       "4  0.033026  0.025328  no_pain  \n",
       "\n",
       "[5 rows x 37 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_index</th>\n",
       "      <th>time</th>\n",
       "      <th>pain_survey_1</th>\n",
       "      <th>pain_survey_2</th>\n",
       "      <th>pain_survey_3</th>\n",
       "      <th>pain_survey_4</th>\n",
       "      <th>joint_00</th>\n",
       "      <th>joint_01</th>\n",
       "      <th>joint_02</th>\n",
       "      <th>joint_03</th>\n",
       "      <th>...</th>\n",
       "      <th>joint_21</th>\n",
       "      <th>joint_22</th>\n",
       "      <th>joint_23</th>\n",
       "      <th>joint_24</th>\n",
       "      <th>joint_25</th>\n",
       "      <th>joint_26</th>\n",
       "      <th>joint_27</th>\n",
       "      <th>joint_28</th>\n",
       "      <th>joint_29</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.094705</td>\n",
       "      <td>0.985281</td>\n",
       "      <td>1.018302</td>\n",
       "      <td>1.010385</td>\n",
       "      <td>...</td>\n",
       "      <td>3.499558e-06</td>\n",
       "      <td>1.945042e-06</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>1.153299e-05</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.017592</td>\n",
       "      <td>0.013508</td>\n",
       "      <td>0.026798</td>\n",
       "      <td>0.027815</td>\n",
       "      <td>no_pain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.135183</td>\n",
       "      <td>1.021175</td>\n",
       "      <td>0.994343</td>\n",
       "      <td>1.052364</td>\n",
       "      <td>...</td>\n",
       "      <td>3.976952e-07</td>\n",
       "      <td>6.765108e-07</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>4.643774e-08</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013352</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013377</td>\n",
       "      <td>0.013716</td>\n",
       "      <td>no_pain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.080745</td>\n",
       "      <td>0.962842</td>\n",
       "      <td>1.009588</td>\n",
       "      <td>0.977169</td>\n",
       "      <td>...</td>\n",
       "      <td>1.533820e-07</td>\n",
       "      <td>1.698525e-07</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>2.424536e-06</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.016225</td>\n",
       "      <td>0.008110</td>\n",
       "      <td>0.024097</td>\n",
       "      <td>0.023105</td>\n",
       "      <td>no_pain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.938017</td>\n",
       "      <td>1.081592</td>\n",
       "      <td>0.998021</td>\n",
       "      <td>0.987283</td>\n",
       "      <td>...</td>\n",
       "      <td>1.006865e-05</td>\n",
       "      <td>5.511079e-07</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>5.432416e-08</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011832</td>\n",
       "      <td>0.007450</td>\n",
       "      <td>0.028613</td>\n",
       "      <td>0.024648</td>\n",
       "      <td>no_pain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.090185</td>\n",
       "      <td>1.032145</td>\n",
       "      <td>1.008710</td>\n",
       "      <td>0.963658</td>\n",
       "      <td>...</td>\n",
       "      <td>4.437265e-06</td>\n",
       "      <td>1.735459e-07</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>5.825366e-08</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.005360</td>\n",
       "      <td>0.002532</td>\n",
       "      <td>0.033026</td>\n",
       "      <td>0.025328</td>\n",
       "      <td>no_pain</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 37 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 157
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-07T19:13:43.401071Z",
     "start_time": "2025-11-07T18:35:34.924926Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df['id'] = df['sample_index'].astype('str') + '_' + df['label'].astype('str')\n",
    "\n",
    "# Identify unique activity executions per user by creating a composite ID\n",
    "df['id'] = df['sample_index'].astype('str') + '_' + df['label'].astype('str')\n",
    "\n",
    "# Print the number of unique activity executions\n",
    "print(f'The dataset is composed of {df[\"id\"].nunique()} different executions')\n",
    "\n",
    "# Count the unique IDs for distinct activity executions\n",
    "n_users = len(df['id'].unique())\n",
    "\n",
    "# Create a custom colour map for better distinction of unique IDs\n",
    "colors = plt.cm.turbo(np.linspace(0, 1, n_users))\n",
    "\n",
    "# Visualise the count of timestamps per unique ID\n",
    "plt.figure(figsize=(17, 5))\n",
    "sns.countplot(\n",
    "    x='id',\n",
    "    data=df,\n",
    "    order=df['id'].value_counts().index,\n",
    "    palette=colors\n",
    ")\n",
    "\n",
    "# Set the title of the plot and disable x-axis labels for clarity\n",
    "plt.title('Per Id Timestamps')\n",
    "plt.xticks([], [])  # Remove x-axis ticks and labels\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ],
   "id": "7bb0ca2f2eafd8b5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset is composed of 661 different executions\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1700x500 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 158
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-07T19:13:43.401605Z",
     "start_time": "2025-11-07T18:35:36.561243Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Get unique user IDs and shuffle them\n",
    "unique_users = df['sample_index'].unique() # 661\n",
    "random.seed(SEED) # Ensure reproducibility of shuffling\n",
    "random.shuffle(unique_users)\n",
    "\n",
    "# Define the number of users for validation and test sets\n",
    "N_VAL_USERS = 100\n",
    "\n",
    "# Calculate the number of users for the training set\n",
    "n_train_users = len(unique_users) - N_VAL_USERS\n",
    "\n",
    "# Split the shuffled user IDs into training, validation, and test sets\n",
    "train_users = unique_users[:n_train_users]\n",
    "val_users = unique_users[n_train_users:n_train_users + N_VAL_USERS]\n",
    "\n",
    "# Split the dataset into training, validation, and test sets based on user IDs\n",
    "df_train = df[df['sample_index'].isin(train_users)]\n",
    "df_val = df[df['sample_index'].isin(val_users)]\n",
    "\n",
    "# Print the shapes of the training, validation, and test sets\n",
    "print(f'Training set shape: {df_train.shape}')\n",
    "print(f'Validation set shape: {df_val.shape}')"
   ],
   "id": "a16e38cedbd06865",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (89760, 38)\n",
      "Validation set shape: (16000, 38)\n"
     ]
    }
   ],
   "execution_count": 159
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-07T19:13:43.402219Z",
     "start_time": "2025-11-07T18:35:36.596800Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define a mapping of activity names to integer labels\n",
    "label_mapping = {\n",
    "    'no_pain': 0,\n",
    "    'low_pain': 1,\n",
    "    'high_pain': 2,\n",
    "}\n",
    "\n",
    "# Map activity names to integers in the training set\n",
    "df_train['label'] = df_train['label'].map(label_mapping)\n",
    "\n",
    "# Map activity names to integers in the validation set\n",
    "df_val['label'] = df_val['label'].map(label_mapping)"
   ],
   "id": "d3a171195f8731b4",
   "outputs": [],
   "execution_count": 160
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-07T19:13:43.403539Z",
     "start_time": "2025-11-07T18:35:36.609701Z"
    }
   },
   "cell_type": "code",
   "source": "df_train.head(5)",
   "id": "7f93a4d7e7efe75f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   sample_index  time  pain_survey_1  pain_survey_2  pain_survey_3  \\\n",
       "0             0     0              2              0              2   \n",
       "1             0     1              2              2              2   \n",
       "2             0     2              2              0              2   \n",
       "3             0     3              2              2              2   \n",
       "4             0     4              2              2              2   \n",
       "\n",
       "   pain_survey_4  joint_00  joint_01  joint_02  joint_03  ...      joint_22  \\\n",
       "0              1  1.094705  0.985281  1.018302  1.010385  ...  1.945042e-06   \n",
       "1              2  1.135183  1.021175  0.994343  1.052364  ...  6.765108e-07   \n",
       "2              2  1.080745  0.962842  1.009588  0.977169  ...  1.698525e-07   \n",
       "3              2  0.938017  1.081592  0.998021  0.987283  ...  5.511079e-07   \n",
       "4              2  1.090185  1.032145  1.008710  0.963658  ...  1.735459e-07   \n",
       "\n",
       "   joint_23      joint_24  joint_25  joint_26  joint_27  joint_28  joint_29  \\\n",
       "0  0.000004  1.153299e-05  0.000004  0.017592  0.013508  0.026798  0.027815   \n",
       "1  0.000006  4.643774e-08  0.000000  0.013352  0.000000  0.013377  0.013716   \n",
       "2  0.000001  2.424536e-06  0.000003  0.016225  0.008110  0.024097  0.023105   \n",
       "3  0.000002  5.432416e-08  0.000000  0.011832  0.007450  0.028613  0.024648   \n",
       "4  0.000002  5.825366e-08  0.000007  0.005360  0.002532  0.033026  0.025328   \n",
       "\n",
       "   label         id  \n",
       "0      0  0_no_pain  \n",
       "1      0  0_no_pain  \n",
       "2      0  0_no_pain  \n",
       "3      0  0_no_pain  \n",
       "4      0  0_no_pain  \n",
       "\n",
       "[5 rows x 38 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_index</th>\n",
       "      <th>time</th>\n",
       "      <th>pain_survey_1</th>\n",
       "      <th>pain_survey_2</th>\n",
       "      <th>pain_survey_3</th>\n",
       "      <th>pain_survey_4</th>\n",
       "      <th>joint_00</th>\n",
       "      <th>joint_01</th>\n",
       "      <th>joint_02</th>\n",
       "      <th>joint_03</th>\n",
       "      <th>...</th>\n",
       "      <th>joint_22</th>\n",
       "      <th>joint_23</th>\n",
       "      <th>joint_24</th>\n",
       "      <th>joint_25</th>\n",
       "      <th>joint_26</th>\n",
       "      <th>joint_27</th>\n",
       "      <th>joint_28</th>\n",
       "      <th>joint_29</th>\n",
       "      <th>label</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.094705</td>\n",
       "      <td>0.985281</td>\n",
       "      <td>1.018302</td>\n",
       "      <td>1.010385</td>\n",
       "      <td>...</td>\n",
       "      <td>1.945042e-06</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>1.153299e-05</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.017592</td>\n",
       "      <td>0.013508</td>\n",
       "      <td>0.026798</td>\n",
       "      <td>0.027815</td>\n",
       "      <td>0</td>\n",
       "      <td>0_no_pain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.135183</td>\n",
       "      <td>1.021175</td>\n",
       "      <td>0.994343</td>\n",
       "      <td>1.052364</td>\n",
       "      <td>...</td>\n",
       "      <td>6.765108e-07</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>4.643774e-08</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013352</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013377</td>\n",
       "      <td>0.013716</td>\n",
       "      <td>0</td>\n",
       "      <td>0_no_pain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.080745</td>\n",
       "      <td>0.962842</td>\n",
       "      <td>1.009588</td>\n",
       "      <td>0.977169</td>\n",
       "      <td>...</td>\n",
       "      <td>1.698525e-07</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>2.424536e-06</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.016225</td>\n",
       "      <td>0.008110</td>\n",
       "      <td>0.024097</td>\n",
       "      <td>0.023105</td>\n",
       "      <td>0</td>\n",
       "      <td>0_no_pain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.938017</td>\n",
       "      <td>1.081592</td>\n",
       "      <td>0.998021</td>\n",
       "      <td>0.987283</td>\n",
       "      <td>...</td>\n",
       "      <td>5.511079e-07</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>5.432416e-08</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011832</td>\n",
       "      <td>0.007450</td>\n",
       "      <td>0.028613</td>\n",
       "      <td>0.024648</td>\n",
       "      <td>0</td>\n",
       "      <td>0_no_pain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.090185</td>\n",
       "      <td>1.032145</td>\n",
       "      <td>1.008710</td>\n",
       "      <td>0.963658</td>\n",
       "      <td>...</td>\n",
       "      <td>1.735459e-07</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>5.825366e-08</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.005360</td>\n",
       "      <td>0.002532</td>\n",
       "      <td>0.033026</td>\n",
       "      <td>0.025328</td>\n",
       "      <td>0</td>\n",
       "      <td>0_no_pain</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 38 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 161
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-07T19:13:43.404732Z",
     "start_time": "2025-11-07T18:35:36.653080Z"
    }
   },
   "cell_type": "code",
   "source": [
    "scale_columns = df_train.columns [2:-2]\n",
    "\n",
    "# Calculate the minimum and maximum values from the training data only\n",
    "mins = df_train[scale_columns].min()\n",
    "maxs = df_train[scale_columns].max()\n",
    "\n",
    "# Apply normalisation to the specified columns in all datasets\n",
    "for column in scale_columns:\n",
    "    # Normalise the training set\n",
    "    df_train[column] = (df_train[column] - mins[column]) / (maxs[column] - mins[column])\n",
    "\n",
    "    # Normalise the validation set\n",
    "    df_val[column] = (df_val[column] - mins[column]) / (maxs[column] - mins[column])"
   ],
   "id": "26a7025c8ae53e14",
   "outputs": [],
   "execution_count": 162
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-07T19:13:43.405345Z",
     "start_time": "2025-11-07T18:35:36.708577Z"
    }
   },
   "cell_type": "code",
   "source": "df_train.head()",
   "id": "b622b27c3103567d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   sample_index  time  pain_survey_1  pain_survey_2  pain_survey_3  \\\n",
       "0             0     0            1.0            0.0            1.0   \n",
       "1             0     1            1.0            1.0            1.0   \n",
       "2             0     2            1.0            0.0            1.0   \n",
       "3             0     3            1.0            1.0            1.0   \n",
       "4             0     4            1.0            1.0            1.0   \n",
       "\n",
       "   pain_survey_4  joint_00  joint_01  joint_02  joint_03  ...      joint_22  \\\n",
       "0            0.5  0.777507  0.738252  0.779512  0.804419  ...  1.374706e-06   \n",
       "1            1.0  0.806256  0.765147  0.761153  0.838021  ...  4.026520e-07   \n",
       "2            1.0  0.767592  0.721439  0.772834  0.777832  ...  1.440847e-08   \n",
       "3            1.0  0.666220  0.810416  0.763971  0.785928  ...  3.065580e-07   \n",
       "4            1.0  0.774297  0.773366  0.772162  0.767017  ...  1.723862e-08   \n",
       "\n",
       "   joint_23      joint_24  joint_25  joint_26  joint_27  joint_28  joint_29  \\\n",
       "0  0.000015  3.162814e-04  0.000004  0.014211  0.011376  0.018978  0.020291   \n",
       "1  0.000022  9.828599e-07  0.000000  0.010745  0.000000  0.009473  0.010006   \n",
       "2  0.000005  6.626013e-05  0.000003  0.013093  0.006830  0.017065  0.016856   \n",
       "3  0.000007  1.199337e-06  0.000000  0.009502  0.006274  0.020264  0.017981   \n",
       "4  0.000006  1.307199e-06  0.000007  0.004212  0.002132  0.023389  0.018477   \n",
       "\n",
       "   label         id  \n",
       "0    0.0  0_no_pain  \n",
       "1    0.0  0_no_pain  \n",
       "2    0.0  0_no_pain  \n",
       "3    0.0  0_no_pain  \n",
       "4    0.0  0_no_pain  \n",
       "\n",
       "[5 rows x 38 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_index</th>\n",
       "      <th>time</th>\n",
       "      <th>pain_survey_1</th>\n",
       "      <th>pain_survey_2</th>\n",
       "      <th>pain_survey_3</th>\n",
       "      <th>pain_survey_4</th>\n",
       "      <th>joint_00</th>\n",
       "      <th>joint_01</th>\n",
       "      <th>joint_02</th>\n",
       "      <th>joint_03</th>\n",
       "      <th>...</th>\n",
       "      <th>joint_22</th>\n",
       "      <th>joint_23</th>\n",
       "      <th>joint_24</th>\n",
       "      <th>joint_25</th>\n",
       "      <th>joint_26</th>\n",
       "      <th>joint_27</th>\n",
       "      <th>joint_28</th>\n",
       "      <th>joint_29</th>\n",
       "      <th>label</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.777507</td>\n",
       "      <td>0.738252</td>\n",
       "      <td>0.779512</td>\n",
       "      <td>0.804419</td>\n",
       "      <td>...</td>\n",
       "      <td>1.374706e-06</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>3.162814e-04</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.014211</td>\n",
       "      <td>0.011376</td>\n",
       "      <td>0.018978</td>\n",
       "      <td>0.020291</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0_no_pain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.806256</td>\n",
       "      <td>0.765147</td>\n",
       "      <td>0.761153</td>\n",
       "      <td>0.838021</td>\n",
       "      <td>...</td>\n",
       "      <td>4.026520e-07</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>9.828599e-07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010745</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009473</td>\n",
       "      <td>0.010006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0_no_pain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.767592</td>\n",
       "      <td>0.721439</td>\n",
       "      <td>0.772834</td>\n",
       "      <td>0.777832</td>\n",
       "      <td>...</td>\n",
       "      <td>1.440847e-08</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>6.626013e-05</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.013093</td>\n",
       "      <td>0.006830</td>\n",
       "      <td>0.017065</td>\n",
       "      <td>0.016856</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0_no_pain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666220</td>\n",
       "      <td>0.810416</td>\n",
       "      <td>0.763971</td>\n",
       "      <td>0.785928</td>\n",
       "      <td>...</td>\n",
       "      <td>3.065580e-07</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>1.199337e-06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009502</td>\n",
       "      <td>0.006274</td>\n",
       "      <td>0.020264</td>\n",
       "      <td>0.017981</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0_no_pain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.774297</td>\n",
       "      <td>0.773366</td>\n",
       "      <td>0.772162</td>\n",
       "      <td>0.767017</td>\n",
       "      <td>...</td>\n",
       "      <td>1.723862e-08</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>1.307199e-06</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.004212</td>\n",
       "      <td>0.002132</td>\n",
       "      <td>0.023389</td>\n",
       "      <td>0.018477</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0_no_pain</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 38 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 163
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-07T19:13:43.405933Z",
     "start_time": "2025-11-07T18:35:36.774707Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 160 timestamps for sample\n",
    "# Define the window size\n",
    "WINDOW_SIZE = 20\n",
    "\n",
    "# Define the stride for overlapping windows\n",
    "STRIDE = 5"
   ],
   "id": "a02d9e8a4544c6fd",
   "outputs": [],
   "execution_count": 164
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-07T19:13:43.414683Z",
     "start_time": "2025-11-07T18:35:36.827128Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define a function to build sequences from the dataset\n",
    "def build_sequences(df, window=200, stride=200):\n",
    "    # Sanity check to ensure the window is divisible by the stride\n",
    "    assert window % stride == 0\n",
    "\n",
    "    # Initialise lists to store sequences and their corresponding labels\n",
    "    dataset = []\n",
    "    labels = []\n",
    "\n",
    "    # Iterate over unique IDs in the DataFrame\n",
    "    for id in df['id'].unique():\n",
    "        # Extract sensor data for the current ID\n",
    "        temp = df[df['id'] == id][scale_columns].values\n",
    "\n",
    "        # Retrieve the activity label for the current ID\n",
    "        label = df[df['id'] == id]['label'].values[0]\n",
    "\n",
    "        # Calculate padding length to ensure full windows\n",
    "        padding_len = window - len(temp) % window\n",
    "\n",
    "        # Create zero padding and concatenate with the data\n",
    "        padding = np.zeros((padding_len, len(scale_columns)), dtype='float32')\n",
    "        temp = np.concatenate((temp, padding))\n",
    "\n",
    "        # Build feature windows and associate them with labels\n",
    "        idx = 0\n",
    "        while idx + window <= len(temp):\n",
    "            dataset.append(temp[idx:idx + window])\n",
    "            labels.append(label)\n",
    "            idx += stride\n",
    "\n",
    "    # Convert lists to numpy arrays for further processing\n",
    "    dataset = np.array(dataset)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    return dataset, labels"
   ],
   "id": "777747b57f0b5d13",
   "outputs": [],
   "execution_count": 165
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-07T19:13:43.415158Z",
     "start_time": "2025-11-07T18:35:36.860646Z"
    }
   },
   "cell_type": "code",
   "source": "print(df['id'].nunique())",
   "id": "fd20bdab622b51e8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "661\n"
     ]
    }
   ],
   "execution_count": 166
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-07T19:13:43.415969Z",
     "start_time": "2025-11-07T18:35:36.897866Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Generate sequences and labels for the training set\n",
    "X_train, y_train = build_sequences(df_train, WINDOW_SIZE, STRIDE)\n",
    "\n",
    "# Generate sequences and labels for the validation set\n",
    "X_val, y_val = build_sequences(df_val, WINDOW_SIZE, STRIDE)\n",
    "\n",
    "# Print the shapes of the generated datasets and their labels\n",
    "X_train.shape, y_train.shape, X_val.shape, y_val.shape"
   ],
   "id": "81e385816e99dabc",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((18513, 20, 35), (18513,), (3300, 20, 35), (3300,))"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 167
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-07T19:13:43.417030Z",
     "start_time": "2025-11-07T18:35:57.344363Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define the input shape based on the training data\n",
    "input_shape = X_train.shape[1:]\n",
    "\n",
    "# Define the number of classes based on the categorical labels\n",
    "num_classes = len(np.unique(y_train))"
   ],
   "id": "6d8821ef656a7dcb",
   "outputs": [],
   "execution_count": 168
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-07T19:13:43.417262Z",
     "start_time": "2025-11-07T18:36:05.872508Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Convert numpy arrays to PyTorch datasets (pairs features with labels)\n",
    "train_ds = TensorDataset(torch.from_numpy(X_train), torch.from_numpy(y_train))\n",
    "val_ds   = TensorDataset(torch.from_numpy(X_val), torch.from_numpy(y_val))"
   ],
   "id": "b009d8bedc9fe7c4",
   "outputs": [],
   "execution_count": 169
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-07T19:13:43.417393Z",
     "start_time": "2025-11-07T18:36:13.181382Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define the batch size, which is the number of samples in each batch\n",
    "BATCH_SIZE = 512"
   ],
   "id": "c46cd95b04430ced",
   "outputs": [],
   "execution_count": 170
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-07T19:13:43.417509Z",
     "start_time": "2025-11-07T18:36:39.705483Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def make_loader(ds, batch_size, shuffle, drop_last):\n",
    "    # Determine optimal number of worker processes for data loading\n",
    "    cpu_cores = os.cpu_count() or 2\n",
    "    num_workers = max(2, min(4, cpu_cores))\n",
    "\n",
    "    # Create DataLoader with performance optimizations\n",
    "    return DataLoader(\n",
    "        ds,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        drop_last=drop_last,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True,  # Faster GPU transfer\n",
    "        pin_memory_device=\"cuda\" if torch.cuda.is_available() else \"\",\n",
    "        prefetch_factor=4,  # Load 4 batches ahead\n",
    "    )"
   ],
   "id": "86f6da99eaf630ce",
   "outputs": [],
   "execution_count": 171
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-07T19:13:43.417686Z",
     "start_time": "2025-11-07T18:36:41.525787Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create data loaders with different settings for each phase\n",
    "train_loader = make_loader(train_ds, batch_size=BATCH_SIZE, shuffle=True, drop_last=False)\n",
    "val_loader   = make_loader(val_ds, batch_size=BATCH_SIZE, shuffle=False, drop_last=False)"
   ],
   "id": "33f7c5cfde129bb4",
   "outputs": [],
   "execution_count": 172
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-07T19:13:43.417881Z",
     "start_time": "2025-11-07T18:36:43.040191Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Get one batch from the training data loader\n",
    "for xb, yb in train_loader:\n",
    "    print(\"Features batch shape:\", xb.shape)\n",
    "    print(\"Labels batch shape:\", yb.shape)\n",
    "    break # Stop after getting one batch"
   ],
   "id": "964d2d743bd9ef56",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features batch shape: torch.Size([512, 20, 35])\n",
      "Labels batch shape: torch.Size([512])\n"
     ]
    }
   ],
   "execution_count": 173
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# MODEL BUILDING",
   "id": "18c42851cd9d8efc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def recurrent_summary(model, input_size):\n",
    "    \"\"\"\n",
    "    Custom summary function that emulates torchinfo's output while correctly\n",
    "    counting parameters for RNN/GRU/LSTM layers.\n",
    "\n",
    "    This function is designed for models whose direct children are\n",
    "    nn.Linear, nn.RNN, nn.GRU, or nn.LSTM layers.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): The model to analyze.\n",
    "        input_size (tuple): Shape of the input tensor (e.g., (seq_len, features)).\n",
    "    \"\"\"\n",
    "\n",
    "    # Dictionary to store output shapes captured by forward hooks\n",
    "    output_shapes = {}\n",
    "    # List to track hook handles for later removal\n",
    "    hooks = []\n",
    "\n",
    "    def get_hook(name):\n",
    "        \"\"\"Factory function to create a forward hook for a specific module.\"\"\"\n",
    "        def hook(module, input, output):\n",
    "            # Handle RNN layer outputs (returns a tuple)\n",
    "            if isinstance(output, tuple):\n",
    "                # output[0]: all hidden states with shape (batch, seq_len, hidden*directions)\n",
    "                shape1 = list(output[0].shape)\n",
    "                shape1[0] = -1  # Replace batch dimension with -1\n",
    "\n",
    "                # output[1]: final hidden state h_n (or tuple (h_n, c_n) for LSTM)\n",
    "                if isinstance(output[1], tuple):  # LSTM case: (h_n, c_n)\n",
    "                    shape2 = list(output[1][0].shape)  # Extract h_n only\n",
    "                else:  # RNN/GRU case: h_n only\n",
    "                    shape2 = list(output[1].shape)\n",
    "\n",
    "                # Replace batch dimension (middle position) with -1\n",
    "                shape2[1] = -1\n",
    "\n",
    "                output_shapes[name] = f\"[{shape1}, {shape2}]\"\n",
    "\n",
    "            # Handle standard layer outputs (e.g., Linear)\n",
    "            else:\n",
    "                shape = list(output.shape)\n",
    "                shape[0] = -1  # Replace batch dimension with -1\n",
    "                output_shapes[name] = f\"{shape}\"\n",
    "        return hook\n",
    "\n",
    "    # 1. Determine the device where model parameters reside\n",
    "    try:\n",
    "        device = next(model.parameters()).device\n",
    "    except StopIteration:\n",
    "        device = torch.device(\"cpu\")  # Fallback for models without parameters\n",
    "\n",
    "    # 2. Create a dummy input tensor with batch_size=1\n",
    "    dummy_input = torch.randn(1, *input_size).to(device)\n",
    "\n",
    "    # 3. Register forward hooks on target layers\n",
    "    # Iterate through direct children of the model (e.g., self.rnn, self.classifier)\n",
    "    for name, module in model.named_children():\n",
    "        if isinstance(module, (nn.Linear, nn.RNN, nn.GRU, nn.LSTM)):\n",
    "            # Register the hook and store its handle for cleanup\n",
    "            hook_handle = module.register_forward_hook(get_hook(name))\n",
    "            hooks.append(hook_handle)\n",
    "\n",
    "    # 4. Execute a dummy forward pass in evaluation mode\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        try:\n",
    "            model(dummy_input)\n",
    "        except Exception as e:\n",
    "            print(f\"Error during dummy forward pass: {e}\")\n",
    "            # Clean up hooks even if an error occurs\n",
    "            for h in hooks:\n",
    "                h.remove()\n",
    "            return\n",
    "\n",
    "    # 5. Remove all registered hooks\n",
    "    for h in hooks:\n",
    "        h.remove()\n",
    "\n",
    "    # --- 6. Print the summary table ---\n",
    "\n",
    "    print(\"-\" * 79)\n",
    "    # Column headers\n",
    "    print(f\"{'Layer (type)':<25} {'Output Shape':<28} {'Param #':<18}\")\n",
    "    print(\"=\" * 79)\n",
    "\n",
    "    total_params = 0\n",
    "    total_trainable_params = 0\n",
    "\n",
    "    # Iterate through modules again to collect and display parameter information\n",
    "    for name, module in model.named_children():\n",
    "        if name in output_shapes:\n",
    "            # Count total and trainable parameters for this module\n",
    "            module_params = sum(p.numel() for p in module.parameters())\n",
    "            trainable_params = sum(p.numel() for p in module.parameters() if p.requires_grad)\n",
    "\n",
    "            total_params += module_params\n",
    "            total_trainable_params += trainable_params\n",
    "\n",
    "            # Format strings for display\n",
    "            layer_name = f\"{name} ({type(module).__name__})\"\n",
    "            output_shape_str = str(output_shapes[name])\n",
    "            params_str = f\"{trainable_params:,}\"\n",
    "\n",
    "            print(f\"{layer_name:<25} {output_shape_str:<28} {params_str:<15}\")\n",
    "\n",
    "    print(\"=\" * 79)\n",
    "    print(f\"Total params: {total_params:,}\")\n",
    "    print(f\"Trainable params: {total_trainable_params:,}\")\n",
    "    print(f\"Non-trainable params: {total_params - total_trainable_params:,}\")\n",
    "    print(\"-\" * 79)"
   ],
   "id": "4c84d554144a5d35"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class RecurrentClassifier(nn.Module):\n",
    "    \"\"\"\n",
    "    Generic RNN classifier (RNN, LSTM, GRU).\n",
    "    Uses the last hidden state for classification.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "            self,\n",
    "            input_size,\n",
    "            hidden_size,\n",
    "            num_layers,\n",
    "            num_classes,\n",
    "            rnn_type='GRU',        # 'RNN', 'LSTM', or 'GRU'\n",
    "            bidirectional=False,\n",
    "            dropout_rate=0.2\n",
    "            ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.rnn_type = rnn_type\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.bidirectional = bidirectional\n",
    "\n",
    "        # Map string name to PyTorch RNN class\n",
    "        rnn_map = {\n",
    "            'RNN': nn.RNN,\n",
    "            'LSTM': nn.LSTM,\n",
    "            'GRU': nn.GRU\n",
    "        }\n",
    "\n",
    "        if rnn_type not in rnn_map:\n",
    "            raise ValueError(\"rnn_type must be 'RNN', 'LSTM', or 'GRU'\")\n",
    "\n",
    "        rnn_module = rnn_map[rnn_type]\n",
    "\n",
    "        # Dropout is only applied between layers (if num_layers > 1)\n",
    "        dropout_val = dropout_rate if num_layers > 1 else 0\n",
    "\n",
    "        # Create the recurrent layer\n",
    "        self.rnn = rnn_module(\n",
    "            input_size=input_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,       # Input shape: (batch, seq_len, features)\n",
    "            bidirectional=bidirectional,\n",
    "            dropout=dropout_val\n",
    "        )\n",
    "\n",
    "        # Calculate input size for the final classifier\n",
    "        if self.bidirectional:\n",
    "            classifier_input_size = hidden_size * 2 # Concat fwd + bwd\n",
    "        else:\n",
    "            classifier_input_size = hidden_size\n",
    "\n",
    "        # Final classification layer\n",
    "        self.classifier = nn.Linear(classifier_input_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x shape: (batch_size, seq_length, input_size)\n",
    "        \"\"\"\n",
    "\n",
    "        # rnn_out shape: (batch_size, seq_len, hidden_size * num_directions)\n",
    "        rnn_out, hidden = self.rnn(x)\n",
    "\n",
    "        # LSTM returns (h_n, c_n), we only need h_n\n",
    "        if self.rnn_type == 'LSTM':\n",
    "            hidden = hidden[0]\n",
    "\n",
    "        # hidden shape: (num_layers * num_directions, batch_size, hidden_size)\n",
    "\n",
    "        if self.bidirectional:\n",
    "            # Reshape to (num_layers, 2, batch_size, hidden_size)\n",
    "            hidden = hidden.view(self.num_layers, 2, -1, self.hidden_size)\n",
    "\n",
    "            # Concat last fwd (hidden[-1, 0, ...]) and bwd (hidden[-1, 1, ...])\n",
    "            # Final shape: (batch_size, hidden_size * 2)\n",
    "            hidden_to_classify = torch.cat([hidden[-1, 0, :, :], hidden[-1, 1, :, :]], dim=1)\n",
    "        else:\n",
    "            # Take the last layer's hidden state\n",
    "            # Final shape: (batch_size, hidden_size)\n",
    "            hidden_to_classify = hidden[-1]\n",
    "\n",
    "        # Get logits\n",
    "        logits = self.classifier(hidden_to_classify)\n",
    "        return logits\n",
    "\n",
    "\n",
    "# Create model and display architecture with parameter count\n",
    "rnn_model = RecurrentClassifier(\n",
    "    input_size=input_shape[-1], # Pass the number of features\n",
    "    hidden_size=128,\n",
    "    num_layers=2,\n",
    "    num_classes=num_classes,\n",
    "    dropout_rate=0.,\n",
    "    rnn_type='RNN'\n",
    "    ).to(device)\n",
    "recurrent_summary(rnn_model, input_size=input_shape)"
   ],
   "id": "6343d76cc20bf6c8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 🧮 **Network and Training Hyperparameters**",
   "id": "a9305b8a1cae4d97"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Training configuration\n",
    "LEARNING_RATE = 1e-3\n",
    "EPOCHS = 500\n",
    "PATIENCE = 50\n",
    "\n",
    "# Architecture\n",
    "HIDDEN_LAYERS = 2        # Hidden layers\n",
    "HIDDEN_SIZE = 128        # Neurons per layer\n",
    "\n",
    "# Regularisation\n",
    "DROPOUT_RATE = 0.2         # Dropout probability\n",
    "L1_LAMBDA = 0            # L1 penalty\n",
    "L2_LAMBDA = 0            # L2 penalty\n",
    "\n",
    "# Set up loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()"
   ],
   "id": "f1dcbe4e5be76a0a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 🧠 **Model Training**",
   "id": "5ce6b22dd6670af4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Initialize best model tracking variables\n",
    "best_model = None\n",
    "best_performance = float('-inf')"
   ],
   "id": "3b8dcfdc6c3a5d1a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def train_one_epoch(model, train_loader, criterion, optimizer, scaler, device, l1_lambda=0, l2_lambda=0):\n",
    "    \"\"\"\n",
    "    Perform one complete training epoch through the entire training dataset.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): The neural network model to train\n",
    "        train_loader (DataLoader): PyTorch DataLoader containing training data batches\n",
    "        criterion (nn.Module): Loss function (e.g., CrossEntropyLoss, MSELoss)\n",
    "        optimizer (torch.optim): Optimization algorithm (e.g., Adam, SGD)\n",
    "        scaler (GradScaler): PyTorch's gradient scaler for mixed precision training\n",
    "        device (torch.device): Computing device ('cuda' for GPU, 'cpu' for CPU)\n",
    "        l1_lambda (float): Lambda for L1 regularization\n",
    "        l2_lambda (float): Lambda for L2 regularization\n",
    "\n",
    "    Returns:\n",
    "        tuple: (average_loss, f1 score) - Training loss and f1 score for this epoch\n",
    "    \"\"\"\n",
    "    model.train()  # Set model to training mode\n",
    "\n",
    "    running_loss = 0.0\n",
    "    all_predictions = []\n",
    "    all_targets = []\n",
    "\n",
    "    # Iterate through training batches\n",
    "    for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "        # Move data to device (GPU/CPU)\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "        # Clear gradients from previous step\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        # Forward pass with mixed precision (if CUDA available)\n",
    "        with torch.amp.autocast(device_type=device.type, enabled=(device.type == 'cuda')):\n",
    "            logits = model(inputs)\n",
    "            loss = criterion(logits, targets)\n",
    "\n",
    "            # Add L1 and L2 regularization\n",
    "            l1_norm = sum(p.abs().sum() for p in model.parameters())\n",
    "            l2_norm = sum(p.pow(2).sum() for p in model.parameters())\n",
    "            loss = loss + l1_lambda * l1_norm + l2_lambda * l2_norm\n",
    "\n",
    "\n",
    "        # Backward pass with gradient scaling\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        # Accumulate metrics\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        predictions = logits.argmax(dim=1)\n",
    "        all_predictions.append(predictions.cpu().numpy())\n",
    "        all_targets.append(targets.cpu().numpy())\n",
    "\n",
    "    # Calculate epoch metrics\n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "    epoch_f1 = f1_score(\n",
    "        np.concatenate(all_targets),\n",
    "        np.concatenate(all_predictions),\n",
    "        average='weighted'\n",
    "    )\n",
    "\n",
    "    return epoch_loss, epoch_f1"
   ],
   "id": "ede88e3edfdd3d50"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def validate_one_epoch(model, val_loader, criterion, device):\n",
    "    \"\"\"\n",
    "    Perform one complete validation epoch through the entire validation dataset.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): The neural network model to evaluate (must be in eval mode)\n",
    "        val_loader (DataLoader): PyTorch DataLoader containing validation data batches\n",
    "        criterion (nn.Module): Loss function used to calculate validation loss\n",
    "        device (torch.device): Computing device ('cuda' for GPU, 'cpu' for CPU)\n",
    "\n",
    "    Returns:\n",
    "        tuple: (average_loss, accuracy) - Validation loss and accuracy for this epoch\n",
    "\n",
    "    Note:\n",
    "        This function automatically sets the model to evaluation mode and disables\n",
    "        gradient computation for efficiency during validation.\n",
    "    \"\"\"\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "\n",
    "    running_loss = 0.0\n",
    "    all_predictions = []\n",
    "    all_targets = []\n",
    "\n",
    "    # Disable gradient computation for validation\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in val_loader:\n",
    "            # Move data to device\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "            # Forward pass with mixed precision (if CUDA available)\n",
    "            with torch.amp.autocast(device_type=device.type, enabled=(device.type == 'cuda')):\n",
    "                logits = model(inputs)\n",
    "                loss = criterion(logits, targets)\n",
    "\n",
    "            # Accumulate metrics\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            predictions = logits.argmax(dim=1)\n",
    "            all_predictions.append(predictions.cpu().numpy())\n",
    "            all_targets.append(targets.cpu().numpy())\n",
    "\n",
    "    # Calculate epoch metrics\n",
    "    epoch_loss = running_loss / len(val_loader.dataset)\n",
    "    epoch_accuracy = f1_score(\n",
    "        np.concatenate(all_targets),\n",
    "        np.concatenate(all_predictions),\n",
    "        average='weighted'\n",
    "    )\n",
    "\n",
    "    return epoch_loss, epoch_accuracy"
   ],
   "id": "2b9b18401705c003"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def log_metrics_to_tensorboard(writer, epoch, train_loss, train_f1, val_loss, val_f1, model):\n",
    "    \"\"\"\n",
    "    Log training metrics and model parameters to TensorBoard for visualization.\n",
    "\n",
    "    Args:\n",
    "        writer (SummaryWriter): TensorBoard SummaryWriter object for logging\n",
    "        epoch (int): Current epoch number (used as x-axis in TensorBoard plots)\n",
    "        train_loss (float): Training loss for this epoch\n",
    "        train_f1 (float): Training f1 score for this epoch\n",
    "        val_loss (float): Validation loss for this epoch\n",
    "        val_f1 (float): Validation f1 score for this epoch\n",
    "        model (nn.Module): The neural network model (for logging weights/gradients)\n",
    "\n",
    "    Note:\n",
    "        This function logs scalar metrics (loss/f1 score) and histograms of model\n",
    "        parameters and gradients, which helps monitor training progress and detect\n",
    "        issues like vanishing/exploding gradients.\n",
    "    \"\"\"\n",
    "    # Log scalar metrics\n",
    "    writer.add_scalar('Loss/Training', train_loss, epoch)\n",
    "    writer.add_scalar('Loss/Validation', val_loss, epoch)\n",
    "    writer.add_scalar('F1/Training', train_f1, epoch)\n",
    "    writer.add_scalar('F1/Validation', val_f1, epoch)\n",
    "\n",
    "    # Log model parameters and gradients\n",
    "    for name, param in model.named_parameters():\n",
    "        if param.requires_grad:\n",
    "            # Check if the tensor is not empty before adding a histogram\n",
    "            if param.numel() > 0:\n",
    "                writer.add_histogram(f'{name}/weights', param.data, epoch)\n",
    "            if param.grad is not None:\n",
    "                # Check if the gradient tensor is not empty before adding a histogram\n",
    "                if param.grad.numel() > 0:\n",
    "                    if param.grad is not None and torch.isfinite(param.grad).all():\n",
    "                        writer.add_histogram(f'{name}/gradients', param.grad.data, epoch)"
   ],
   "id": "d685e5c47b750748"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def fit(model, train_loader, val_loader, epochs, criterion, optimizer, scaler, device,\n",
    "        l1_lambda=0, l2_lambda=0, patience=0, evaluation_metric=\"val_f1\", mode='max',\n",
    "        restore_best_weights=True, writer=None, verbose=10, experiment_name=\"\"):\n",
    "    \"\"\"\n",
    "    Train the neural network model on the training data and validate on the validation data.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): The neural network model to train\n",
    "        train_loader (DataLoader): PyTorch DataLoader containing training data batches\n",
    "        val_loader (DataLoader): PyTorch DataLoader containing validation data batches\n",
    "        epochs (int): Number of training epochs\n",
    "        criterion (nn.Module): Loss function (e.g., CrossEntropyLoss, MSELoss)\n",
    "        optimizer (torch.optim): Optimization algorithm (e.g., Adam, SGD)\n",
    "        scaler (GradScaler): PyTorch's gradient scaler for mixed precision training\n",
    "        device (torch.device): Computing device ('cuda' for GPU, 'cpu' for CPU)\n",
    "        l1_lambda (float): L1 regularization coefficient (default: 0)\n",
    "        l2_lambda (float): L2 regularization coefficient (default: 0)\n",
    "        patience (int): Number of epochs to wait for improvement before early stopping (default: 0)\n",
    "        evaluation_metric (str): Metric to monitor for early stopping (default: \"val_f1\")\n",
    "        mode (str): 'max' for maximizing the metric, 'min' for minimizing (default: 'max')\n",
    "        restore_best_weights (bool): Whether to restore model weights from best epoch (default: True)\n",
    "        writer (SummaryWriter, optional): TensorBoard SummaryWriter object for logging (default: None)\n",
    "        verbose (int, optional): Frequency of printing training progress (default: 10)\n",
    "        experiment_name (str, optional): Experiment name for saving models (default: \"\")\n",
    "\n",
    "    Returns:\n",
    "        tuple: (model, training_history) - Trained model and metrics history\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize metrics tracking\n",
    "    training_history = {\n",
    "        'train_loss': [], 'val_loss': [],\n",
    "        'train_f1': [], 'val_f1': []\n",
    "    }\n",
    "\n",
    "    # Configure early stopping if patience is set\n",
    "    if patience > 0:\n",
    "        patience_counter = 0\n",
    "        best_metric = float('-inf') if mode == 'max' else float('inf')\n",
    "        best_epoch = 0\n",
    "\n",
    "    print(f\"Training {epochs} epochs...\")\n",
    "\n",
    "    # Main training loop: iterate through epochs\n",
    "    for epoch in range(1, epochs + 1):\n",
    "\n",
    "        # Forward pass through training data, compute gradients, update weights\n",
    "        train_loss, train_f1 = train_one_epoch(\n",
    "            model, train_loader, criterion, optimizer, scaler, device, l1_lambda, l2_lambda\n",
    "        )\n",
    "\n",
    "        # Evaluate model on validation data without updating weights\n",
    "        val_loss, val_f1 = validate_one_epoch(\n",
    "            model, val_loader, criterion, device\n",
    "        )\n",
    "\n",
    "        # Store metrics for plotting and analysis\n",
    "        training_history['train_loss'].append(train_loss)\n",
    "        training_history['val_loss'].append(val_loss)\n",
    "        training_history['train_f1'].append(train_f1)\n",
    "        training_history['val_f1'].append(val_f1)\n",
    "\n",
    "        # Write metrics to TensorBoard for visualization\n",
    "        if writer is not None:\n",
    "            log_metrics_to_tensorboard(\n",
    "                writer, epoch, train_loss, train_f1, val_loss, val_f1, model\n",
    "            )\n",
    "\n",
    "        # Print progress every N epochs or on first epoch\n",
    "        if verbose > 0:\n",
    "            if epoch % verbose == 0 or epoch == 1:\n",
    "                print(f\"Epoch {epoch:3d}/{epochs} | \"\n",
    "                    f\"Train: Loss={train_loss:.4f}, F1 Score={train_f1:.4f} | \"\n",
    "                    f\"Val: Loss={val_loss:.4f}, F1 Score={val_f1:.4f}\")\n",
    "\n",
    "        # Early stopping logic: monitor metric and save best model\n",
    "        if patience > 0:\n",
    "            current_metric = training_history[evaluation_metric][-1]\n",
    "            is_improvement = (current_metric > best_metric) if mode == 'max' else (current_metric < best_metric)\n",
    "\n",
    "            if is_improvement:\n",
    "                best_metric = current_metric\n",
    "                best_epoch = epoch\n",
    "                torch.save(model.state_dict(), \"models/\"+experiment_name+'_model.pt')\n",
    "                patience_counter = 0\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "                if patience_counter >= patience:\n",
    "                    print(f\"Early stopping triggered after {epoch} epochs.\")\n",
    "                    break\n",
    "\n",
    "    # Restore best model weights if early stopping was used\n",
    "    if restore_best_weights and patience > 0:\n",
    "        model.load_state_dict(torch.load(\"models/\"+experiment_name+'_model.pt'))\n",
    "        print(f\"Best model restored from epoch {best_epoch} with {evaluation_metric} {best_metric:.4f}\")\n",
    "\n",
    "    # Save final model if no early stopping\n",
    "    if patience == 0:\n",
    "        torch.save(model.state_dict(), \"models/\"+experiment_name+'_model.pt')\n",
    "\n",
    "    # Close TensorBoard writer\n",
    "    if writer is not None:\n",
    "        writer.close()\n",
    "\n",
    "    return model, training_history"
   ],
   "id": "31b8d0a71494b339"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create model and display architecture with parameter count\n",
    "rnn_model = RecurrentClassifier(\n",
    "    input_size=input_shape[-1], # Pass the number of features\n",
    "    hidden_size=HIDDEN_SIZE,\n",
    "    num_layers=HIDDEN_LAYERS,\n",
    "    num_classes=num_classes,\n",
    "    dropout_rate=DROPOUT_RATE,\n",
    "    bidirectional=False,\n",
    "    rnn_type='RNN'\n",
    "    ).to(device)\n",
    "recurrent_summary(rnn_model, input_size=input_shape)\n",
    "\n",
    "# Set up TensorBoard logging and save model architecture\n",
    "experiment_name = \"rnn\"\n",
    "writer = SummaryWriter(\"./\"+logs_dir+\"/\"+experiment_name)\n",
    "x = torch.randn(1, input_shape[0], input_shape[1]).to(device)\n",
    "writer.add_graph(rnn_model, x)\n",
    "\n",
    "# Define optimizer with L2 regularization\n",
    "optimizer = torch.optim.AdamW(rnn_model.parameters(), lr=LEARNING_RATE, weight_decay=L2_LAMBDA)\n",
    "\n",
    "# Enable mixed precision training for GPU acceleration\n",
    "scaler = torch.amp.GradScaler(enabled=(device.type == 'cuda'))"
   ],
   "id": "17ac4fd4441706aa"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "%%time\n",
    "# Train model and track training history\n",
    "rnn_model, training_history = fit(\n",
    "    model=rnn_model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    epochs=EPOCHS,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    scaler=scaler,\n",
    "    device=device,\n",
    "    writer=writer,\n",
    "    verbose=1,\n",
    "    experiment_name=\"rnn\",\n",
    "    patience=PATIENCE\n",
    "    )\n",
    "\n",
    "# Update best model if current performance is superior\n",
    "if training_history['val_f1'][-1] > best_performance:\n",
    "    best_model = rnn_model\n",
    "    best_performance = training_history['val_f1'][-1]"
   ],
   "id": "c01bea3ad795c191"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
